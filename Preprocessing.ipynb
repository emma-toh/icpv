{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ba6f11",
   "metadata": {},
   "source": [
    "## import data and merge readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92839e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaac4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_df = pd.read_csv(\"../dynamic_info_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0543c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_readings(row, col_name_from, col_name_into):\n",
    "    \"\"\"Merge readings from 2 columns of data:\n",
    "    \n",
    "    if col_name_from's value is NaN, it is replaced with value \n",
    "    from col_name_into\n",
    "    \"\"\"\n",
    "    if not np.isnan(row[col_name_from]):\n",
    "        return row[col_name_from]\n",
    "    return row[col_name_into]\n",
    "\n",
    "chart_cols = [\n",
    "    'cvp', \n",
    "    'temperature', \n",
    "    'heartrate', \n",
    "    'respiration',\n",
    "    'systemicsystolic',\n",
    "    'systemicdiastolic',\n",
    "    'systemicmean'      \n",
    "]\n",
    "nurse_cols = [\n",
    "    'CVP - CVP', \n",
    "    'Temperature - Temperature (C)', \n",
    "    'Heart Rate - Heart Rate', \n",
    "    'Respiratory Rate - Respiratory Rate',\n",
    "    'Invasive BP - Invasive BP Systolic',\n",
    "    'Invasive BP - Invasive BP Diastolic', \n",
    "    'Invasive BP - Invasive BP Mean'\n",
    "]\n",
    "\n",
    "# Merge chart and nurse readings into a single column, followed by removing \n",
    "# original columns\n",
    "for i in range(7):\n",
    "    dynamic_df[chart_cols[i] + \"_merged\"] = dynamic_df.apply(\n",
    "        lambda x:merge_readings(x, nurse_cols[i], chart_cols[i]), \n",
    "        axis=1\n",
    "    )\n",
    "dynamic_df = dynamic_df.drop(columns=chart_cols+nurse_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56613be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging in non-invasive BP measurements as well to reduce the number of \n",
    "# missing BP measurements\n",
    "nurse_cols = [\n",
    "    'systemicsystolic_merged', \n",
    "    'systemicdiastolic_merged', \n",
    "    'systemicmean_merged',\n",
    "]\n",
    "chart_cols = [\n",
    "    'Non-Invasive BP - Non-Invasive BP Systolic', \n",
    "    'Non-Invasive BP - Non-Invasive BP Diastolic', \n",
    "    'Non-Invasive BP - Non-Invasive BP Mean',\n",
    "]\n",
    "\n",
    "final_col_names = [\n",
    "    'Invasive and Non-Invasive BP Systolic merged',\n",
    "    'Invasive and Non-Invasive BP Diastolic merged',\n",
    "    'Invasive and Non-Invasive BP Mean merged',\n",
    "]\n",
    "\n",
    "for i in range(3):\n",
    "    dynamic_df[final_col_names[i]] = dynamic_df.apply(\n",
    "        lambda x:merge_readings(x, nurse_cols[i], chart_cols[i]), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# (dynamic_df[\"cvp\"].isna() | dynamic_df['CVP - CVP'].isna()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10b4e59-71e6-4a32-bbe0-978d2431fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_hypertension = {}\n",
    "for uid in dynamic_df[\"patientunitstayid\"].unique():\n",
    "    has_hypertension[uid] = int(any(\n",
    "                                dynamic_df[dynamic_df[\"patientunitstayid\"] == uid][\"icp\"]\n",
    "                                .rolling(6)\n",
    "                                .apply(lambda x: (x > 22).sum() > 4, raw=True)\n",
    "                                .dropna()\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f17e5a",
   "metadata": {},
   "source": [
    "## Define the ICPV columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc165b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = dynamic_df[[\n",
    "    \"patientunitstayid\",\n",
    "    \"observationoffset\",\n",
    "    \"icp\",\n",
    "    \"sao2\",\n",
    "    \"etco2\",\n",
    "    \"pasystolic\",\n",
    "    \"padiastolic\",\n",
    "    \"pamean\",\n",
    "    \"Glasgow coma score - GCS Total\",\n",
    "    \"sodium\",\n",
    "    \"glucose\",\n",
    "    \"cvp_merged\",\n",
    "    \"temperature_merged\",\n",
    "    \"heartrate_merged\",\n",
    "    \"respiration_merged\",\n",
    "    \"Invasive and Non-Invasive BP Systolic merged\",\n",
    "    \"Invasive and Non-Invasive BP Diastolic merged\",\n",
    "    \"Invasive and Non-Invasive BP Mean merged\",\n",
    "    \"Intracranial operations_cumsum\",\n",
    "]].copy()\n",
    "##calculate CPP\n",
    "df_a['CPP'] = df_a[\"Invasive and Non-Invasive BP Mean merged\"] - df_a['icp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d30488f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##RSD Definition\n",
    "df_a['stddev_roll_10'] = df_a['icp'].rolling(2).std()\n",
    "df_a['stddev_roll_15'] = df_a['icp'].rolling(3).std()\n",
    "df_a['stddev_roll_20'] = df_a['icp'].rolling(4).std()\n",
    "df_a['stddev_roll_30'] = df_a['icp'].rolling(6).std()\n",
    "df_a['stddev_roll_45'] = df_a['icp'].rolling(9).std()\n",
    "df_a['stddev_roll_60'] = df_a['icp'].rolling(12).std()\n",
    "df_a['stddev_roll_70'] = df_a['icp'].rolling(14).std()\n",
    "df_a['stddev_roll_80'] = df_a['icp'].rolling(16).std()\n",
    "df_a['stddev_roll_90'] = df_a['icp'].rolling(18).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb7ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a['mean_roll_10_min'] = df_a['icp'].rolling(2).mean()\n",
    "df_a['icpv_new_10'] = np.abs(df_a['icp'] - df_a['mean_roll_10_min'])\n",
    "\n",
    "df_a['mean_roll_15_min'] = df_a['icp'].rolling(3).mean()\n",
    "df_a['icpv_new_15'] = np.abs(df_a['icp'] - df_a['mean_roll_15_min'])\n",
    "\n",
    "df_a['mean_roll_20_min'] = df_a['icp'].rolling(4).mean()\n",
    "df_a['icpv_new_20'] = np.abs(df_a['icp'] - df_a['mean_roll_20_min'])\n",
    "\n",
    "df_a['mean_roll_30_min'] = df_a['icp'].rolling(6).mean()\n",
    "df_a['icpv_new_30'] = np.abs(df_a['icp'] - df_a['mean_roll_30_min'])\n",
    "\n",
    "df_a['mean_roll_45_min'] = df_a['icp'].rolling(9).mean()\n",
    "df_a['icpv_new_45'] = np.abs(df_a['icp'] - df_a['mean_roll_45_min'])\n",
    "\n",
    "df_a['mean_roll_60_min'] = df_a['icp'].rolling(12).mean()\n",
    "df_a['icpv_new_60'] = np.abs(df_a['icp'] - df_a['mean_roll_60_min'])\n",
    "\n",
    "df_a['mean_roll_70_min'] = df_a['icp'].rolling(14).mean()\n",
    "df_a['icpv_new_70'] = np.abs(df_a['icp'] - df_a['mean_roll_70_min'])\n",
    "\n",
    "df_a['mean_roll_80_min'] = df_a['icp'].rolling(16).mean()\n",
    "df_a['icpv_new_80'] = np.abs(df_a['icp'] - df_a['mean_roll_80_min'])\n",
    "\n",
    "df_a['mean_roll_90_min'] = df_a['icp'].rolling(18).mean()\n",
    "df_a['icpv_new_90'] = np.abs(df_a['icp'] - df_a['mean_roll_90_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "836002e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##mean ICP per patient -- not for LSTM analysis\n",
    "df_a['ICPmean'] = df_a.groupby('patientunitstayid')['icp'].transform('mean')\n",
    "df_a['icpv_mean_def2_15'] = df_a.groupby('patientunitstayid')['icpv_new_15'].transform('mean')\n",
    "df_a['icpv_var_def2_15'] = df_a.groupby('patientunitstayid')['icpv_new_15'].transform('var')\n",
    "df_a['icpv_mean_def2_20'] = df_a.groupby('patientunitstayid')['icpv_new_20'].transform('mean')\n",
    "df_a['icpv_var_def2_20'] = df_a.groupby('patientunitstayid')['icpv_new_20'].transform('var')\n",
    "df_a['icpv_mean_def2_30'] = df_a.groupby('patientunitstayid')['icpv_new_30'].transform('mean')\n",
    "df_a['icpv_var_def2_30'] = df_a.groupby('patientunitstayid')['icpv_new_30'].transform('var')\n",
    "df_a['icpv_mean_def2_45'] = df_a.groupby('patientunitstayid')['icpv_new_45'].transform('mean')\n",
    "df_a['icpv_var_def2_45'] = df_a.groupby('patientunitstayid')['icpv_new_45'].transform('var')\n",
    "df_a['icpv_mean_def2_60'] = df_a.groupby('patientunitstayid')['icpv_new_60'].transform('mean')\n",
    "df_a['icpv_var_def2_60'] = df_a.groupby('patientunitstayid')['icpv_new_60'].transform('var')\n",
    "df_a['icpv_mean_def1_15'] = df_a.groupby('patientunitstayid')['stddev_roll_15'].transform('mean')\n",
    "df_a['icpv_var_def1_15'] = df_a.groupby('patientunitstayid')['stddev_roll_15'].transform('var')\n",
    "df_a['icpv_mean_def1_20'] = df_a.groupby('patientunitstayid')['stddev_roll_20'].transform('mean')\n",
    "df_a['icpv_var_def1_20'] = df_a.groupby('patientunitstayid')['stddev_roll_20'].transform('var')\n",
    "df_a['icpv_mean_def1_30'] = df_a.groupby('patientunitstayid')['stddev_roll_30'].transform('mean')\n",
    "df_a['icpv_var_def1_30'] = df_a.groupby('patientunitstayid')['stddev_roll_30'].transform('var')\n",
    "df_a['icpv_mean_def1_45'] = df_a.groupby('patientunitstayid')['stddev_roll_45'].transform('mean')\n",
    "df_a['icpv_var_def1_45'] = df_a.groupby('patientunitstayid')['stddev_roll_45'].transform('var')\n",
    "df_a['icpv_mean_def1_60'] = df_a.groupby('patientunitstayid')['stddev_roll_60'].transform('mean')\n",
    "df_a['icpv_var_def1_60'] = df_a.groupby('patientunitstayid')['stddev_roll_60'].transform('var')\n",
    "\n",
    "df_a['icpv_mean_def1_10'] = df_a.groupby('patientunitstayid')['stddev_roll_10'].transform('mean')\n",
    "df_a['icpv_var_def1_10'] = df_a.groupby('patientunitstayid')['stddev_roll_10'].transform('var')\n",
    "df_a['icpv_mean_def1_70'] = df_a.groupby('patientunitstayid')['stddev_roll_70'].transform('mean')\n",
    "df_a['icpv_var_def1_70'] = df_a.groupby('patientunitstayid')['stddev_roll_70'].transform('var')\n",
    "df_a['icpv_mean_def1_80'] = df_a.groupby('patientunitstayid')['stddev_roll_80'].transform('mean')\n",
    "df_a['icpv_var_def1_80'] = df_a.groupby('patientunitstayid')['stddev_roll_80'].transform('var')\n",
    "df_a['icpv_mean_def1_90'] = df_a.groupby('patientunitstayid')['stddev_roll_90'].transform('mean')\n",
    "df_a['icpv_var_def1_90'] = df_a.groupby('patientunitstayid')['stddev_roll_90'].transform('var')\n",
    "df_a['icpv_mean_def2_10'] = df_a.groupby('patientunitstayid')['icpv_new_10'].transform('mean')\n",
    "df_a['icpv_var_def2_10'] = df_a.groupby('patientunitstayid')['icpv_new_10'].transform('var')\n",
    "df_a['icpv_mean_def2_70'] = df_a.groupby('patientunitstayid')['icpv_new_70'].transform('mean')\n",
    "df_a['icpv_var_def2_70'] = df_a.groupby('patientunitstayid')['icpv_new_70'].transform('var')\n",
    "df_a['icpv_mean_def2_80'] = df_a.groupby('patientunitstayid')['icpv_new_80'].transform('mean')\n",
    "df_a['icpv_var_def2_80'] = df_a.groupby('patientunitstayid')['icpv_new_80'].transform('var')\n",
    "df_a['icpv_mean_def2_90'] = df_a.groupby('patientunitstayid')['icpv_new_90'].transform('mean')\n",
    "df_a['icpv_var_def2_90'] = df_a.groupby('patientunitstayid')['icpv_new_90'].transform('var')\n",
    "\n",
    "#df_a['icp_v2'] = df_a['icp'] - df_a['ICPV1']\n",
    "#df_a['var_v2'] = df_a.groupby('patientunitstayid')['icp_v2'].transform('var')\n",
    "#df_a['icp_var'] = df_a.groupby('patientunitstayid')['icp'].transform('var')\n",
    "\n",
    "df_a.to_csv(\"df_a_dataset.csv\")\n",
    "\n",
    "##if want to create the table for per patient instead of per entry\n",
    "## df_one_patient = df_a.groupby('patientunitstayid').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b8ef5e5-cf45-42b6-b81a-32a2e5a2066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1949970, 84)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15150824",
   "metadata": {},
   "source": [
    "## Static DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0470cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = pd.read_csv(\"../static_info_labelled.csv\")\n",
    "\n",
    "#select which columns you want to use in the static df here:\n",
    "static_df_used = static_df.dropna(subset=[\"BMI\", \"GCS\"]).drop(columns=['TBI','label','IH','AIS','CVT','HE','CNC','ethnicity','unitdischargestatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcc15d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(static_df_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5e735",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c27633d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_df_datathon = df_a[[\n",
    "    \"patientunitstayid\", \n",
    "    \"observationoffset\", \n",
    "    \"icp\",\n",
    "    'stddev_roll_10', 'stddev_roll_15', 'stddev_roll_20', \n",
    "    'stddev_roll_30', 'stddev_roll_45', 'stddev_roll_60', \n",
    "    'stddev_roll_70', 'stddev_roll_80', 'stddev_roll_90', \n",
    "    'icpv_new_10', 'icpv_new_15', 'icpv_new_20', \n",
    "    'icpv_new_30', 'icpv_new_45', 'icpv_new_60', \n",
    "    'icpv_new_70', 'icpv_new_80', 'icpv_new_90'\n",
    "]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "902fcbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868,)\n"
     ]
    }
   ],
   "source": [
    "#split into training and testing sets\n",
    "sample_patients = np.array(list(set(df_a[\"patientunitstayid\"].unique()) & set(static_df_used[\"patientunitstayid\"])))\n",
    "print(sample_patients.shape)\n",
    "sets = np.array_split(sample_patients, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e34091",
   "metadata": {},
   "source": [
    "## Sample Extractor Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1295909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the slide to 1!\n",
    "\n",
    "def sample_extractor(df, static_df, patients, col_name, input_len=18, label_len=6, offset_len=6, slide=1, max_samples=200):\n",
    "    \"\"\"Generates up to <max_samples> samples from patients\n",
    "    Sample window:\n",
    "        ------------------------------------------------\n",
    "        |       input            | offset |    label   |\n",
    "        ------------------------------------------------\n",
    "    :param df: dataframe of patient records\n",
    "    :param static_df: dataframe of patient static records\n",
    "    :param patients: list of patients to extract records from\n",
    "    :param col_name: str or list of column names from df to extract as features.\n",
    "                     Feature columns can only contain numeric values\n",
    "    :param input_len: int Number of timestamps as input\n",
    "    :param label_len: int Number of timestamps as output\n",
    "    :param offset_len: int Number of timestamps to skip between input and label. Defaults to 0\n",
    "    :param slide: int Number of timestamps to slide the current window to extract the next sample\n",
    "    :param max_samples: int Maximum number of samples to extract from each patient. Defaults to 50\n",
    "\n",
    "    :return: np.ndarray of features extracted split as samples with shape=\n",
    "             (number of samples, input_len + label_len, number of features = len(col_name))\n",
    "             Input, labels can be separated from the array via:\n",
    "                input, labels = array[:, :input_len, :], array[:, input_len:, :]\n",
    "    \"\"\"\n",
    "    # list to store extracted dynamic and static samples\n",
    "    samples = []\n",
    "    static_samples = []\n",
    "    \n",
    "    # keeps track of start position of samples extracted\n",
    "    starts = []\n",
    "    for patient in patients:\n",
    "        # keep track of number of samples extracted from each sample\n",
    "        sample_count = 0\n",
    "        \n",
    "        static_info = static_df[static_df['patientunitstayid']==patient].iloc[:,2:].values.flatten()\n",
    "        \n",
    "        # Extract contiguous time blocks by:\n",
    "        # 1. Extract patient readings\n",
    "        patient_df = df[df['patientunitstayid'] == patient]\n",
    "        # 2. calculate change in time in minutes between consecutive observations. \n",
    "        diff = patient_df[\"observationoffset\"].diff()\n",
    "        # 3. If the difference is not equal to 5 mins, that suggests missing/skipped observations\n",
    "        # diff_index then stores the row index of observations that are taken more than 5 mins\n",
    "        # after the previous observation, which are the start index of contiguous observations\n",
    "        diff_index = list(diff[diff != 5].index)\n",
    "        \n",
    "        # For each start index of contiguous observations\n",
    "        for i in range(len(diff_index)):\n",
    "            # if i is the last index, the time block is i to the last observation\n",
    "            if i == len(diff_index) - 1:\n",
    "                feature_time_series = patient_df[col_name].loc[diff_index[i]:, ].to_numpy()\n",
    "            # else, the time block is from i to before the next start index\n",
    "            else:\n",
    "                feature_time_series = patient_df[col_name].loc[diff_index[i]:diff_index[i+1], ].to_numpy()\n",
    "            \n",
    "            # if the feature matrix is 1D (when only 1 feature is chosen), make feature matrix 2D\n",
    "            if len(feature_time_series.shape) == 1:\n",
    "                feature_time_series = feature_time_series[..., np.newaxis]\n",
    "            \n",
    "            # starting from time 0:\n",
    "            start = 0\n",
    "            # while there are enough observations to extract another sample from this timeblock\n",
    "            # or less than <max_samples> samples have been extracted\n",
    "            while start + input_len + offset_len + label_len < len(feature_time_series) and sample_count < max_samples:\n",
    "                # Extract input and label features starting from <start> position\n",
    "                sample = np.concatenate((\n",
    "                    # <input_len> number of observations as input\n",
    "                    feature_time_series[start:start+input_len, :],\n",
    "                    # <label_len> number of observations as label, after <offset_len> \n",
    "                    # number of observations skipped\n",
    "                    feature_time_series[start + input_len + offset_len:start + input_len + offset_len + label_len, :]\n",
    "                ), axis=0)\n",
    "                \n",
    "                # store extracted dynamic and static variables, as well as time offset of \n",
    "                # first observation in sample\n",
    "                samples.append(sample)\n",
    "                starts.append(start+input_len)\n",
    "                start += slide\n",
    "                sample_count += 1\n",
    "                # Get the patient's static info\n",
    "                static_samples.append(static_info)\n",
    "    return np.stack(samples),np.stack(static_samples), np.stack(starts)\n",
    "  \n",
    "# input_len = 18\n",
    "# offset_len = 6\n",
    "# label_len = 6\n",
    "# sliding_interval = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978dbe8b",
   "metadata": {},
   "source": [
    "## Extract the npy files - one by one lol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63a56122-f06f-4c77-9d6f-dd7c2f73c10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patientunitstayid', 'observationoffset', 'icp', 'stddev_roll_10',\n",
       "       'stddev_roll_15', 'stddev_roll_20', 'stddev_roll_30', 'stddev_roll_45',\n",
       "       'stddev_roll_60', 'stddev_roll_70', 'stddev_roll_80', 'stddev_roll_90',\n",
       "       'icpv_new_10', 'icpv_new_15', 'icpv_new_20', 'icpv_new_30',\n",
       "       'icpv_new_45', 'icpv_new_60', 'icpv_new_70', 'icpv_new_80',\n",
       "       'icpv_new_90'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_df_datathon.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38bc8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used at training time instead\n",
    "# def is_sustained_increased_icp(vals):\n",
    "#     return (vals > 22).sum(axis=1) > 4\n",
    "\n",
    "\n",
    "# for each of the columns of interest (default setting)\n",
    "for patients in sets:\n",
    "    cols_of_int = dynamic_df_datathon.columns[2:]\n",
    "    \n",
    "    # Extract samples with all features; feature selection at training time\n",
    "    dynamic, static_x, _ = sample_extractor(\n",
    "        dynamic_df_datathon, static_df_used, patients, cols_of_int, \n",
    "        input_len=18, label_len=6, offset_len=6, slide=1, max_samples=100\n",
    "    )\n",
    "    \n",
    "    dynamic_x = dynamic[:, :18, :]\n",
    "    dynamic_y = dynamic[:, 18:, 0]\n",
    "    \n",
    "    # Get number of values to replace with 0 based on time (integer at the end of column name)\n",
    "    # for all columns except icp column(column 0)\n",
    "    for i, col_of_int in enumerate(cols_of_int[1:]):\n",
    "        num_zeros = int(col_of_int.split(\"_\")[-1]) // 5 - 1\n",
    "        dynamic_x[:, :num_zeros, 1 + i] = 0\n",
    "    \n",
    "    with open(f'dataset/train_test_allcols_label6_offset6_slide1_max100.npy', 'ab') as f:\n",
    "        np.save(f, dynamic_x)\n",
    "        np.save(f, static_x)\n",
    "        np.save(f, dynamic_y)\n",
    "        \n",
    "for patients in sets:\n",
    "    cols_of_int = dynamic_df_datathon.columns[2:]\n",
    "    \n",
    "    # Extract samples with all features; feature selection at training time\n",
    "    dynamic, static_x, _ = sample_extractor(\n",
    "        dynamic_df_datathon, static_df_used, patients, cols_of_int, \n",
    "        input_len=18, label_len=12, offset_len=0, slide=1, max_samples=100\n",
    "    )\n",
    "    \n",
    "    dynamic_x = dynamic[:, :18, :]\n",
    "    dynamic_y = dynamic[:, 18:, 0]\n",
    "    \n",
    "    # Get number of values to replace with 0 based on time (integer at the end of column name)\n",
    "    # for all columns except icp column(column 0)\n",
    "    for i, col_of_int in enumerate(cols_of_int[1:]):\n",
    "        num_zeros = int(col_of_int.split(\"_\")[-1]) // 5 - 1\n",
    "        dynamic_x[:, :num_zeros, 1 + i] = 0\n",
    "    \n",
    "    with open(f'dataset/train_test_allcols_label12_offset0_slide1_max100.npy', 'ab') as f:\n",
    "        np.save(f, dynamic_x)\n",
    "        np.save(f, static_x)\n",
    "        np.save(f, dynamic_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b22624f6-f042-47d5-83c3-37d0ce9a1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataset column names, just in case:\n",
    "with open(\"dataset/dynam_col_names.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(cols_of_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9dbcb954-2483-423d-9768-026c648e9654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17170, 18, 19), (17170, 12), (17170, 3))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_x.shape, dynamic_y.shape, static_x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
